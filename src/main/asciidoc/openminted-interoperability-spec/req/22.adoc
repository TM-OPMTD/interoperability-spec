=== The Workflow Engine Should Permit Saving Experimental Conditions in a Workflow

[%hardbreaks]
[small]#*_Concreteness:_* __abstract__#
[small]#*_Strength:_*     __recommended__#
[small]#*_Category:_*     __WG1__,__WG4__#
[small]#*_Status:_*       __final__#



For reproducibility reasons extract and save/export (?) the exact experimental conditions of a workflow, such as which input files used (knowledge base/corpus), which components  are used and in what order, which are the values of the parameters required per component, etc.
(Requirement extracted from Interoperability Scenario WG1-4)


// Below is an example of how a compliance evaluation table could look. This is presently optional
// and may be moved to a more structured/principled format later maintained in separate files.
[cols="2,1,4,1"]
|====
|Product|Compliant|Justification|Status

| Alvis
| unknown
| ...
| draft

| ARGO/U-Compare
| unknown
| ...
| draft

| DKPro Core
| partial
| DKPro Core readers adds a DocumentMetaData annotation to each document which contains basic information from where the document was obtained and how it can be idenfified (usually a file URL). Minimal information about the components/models that were used is added as annotations to the documents as well. This is mainly used as supplementary information to the tagset descriptions that DKPro Core usually adds to the document (i.e. which component/model was used to generate the annotations in a given layer and which tagset was used). A comprehensive recording of components and parameters is left to the workflow engine (i.e. UIMA) and/or to the executing environment. E.g. for building experiements, we sometimes use DKPro Lab, which also keeps track of configuration information of individual components.
| draft

| GATE
| unknown
| ...
| draft

| ILSP
| unknown
| ...
| draft
|====
